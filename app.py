import os
import json
import pdfplumber
import re
import requests
from flask import Flask, request, jsonify
from flask_cors import CORS
from concurrent.futures import ThreadPoolExecutor

app = Flask(__name__)
# Configuration CORS simple pour tous les endpoints
CORS(app, origins="*", methods=["GET", "POST", "OPTIONS"], allow_headers=["Content-Type"])

# Configuration du mod√®le IA
OLLAMA_API_URL = "https://agtelecom-ollama.yhmr4j.easypanel.host/api/generate"
OLLAMA_MODEL = "qwen2.5:1.5b"

def extract_pdf_data(file_path):
    """Extrait les donn√©es du PDF avec pdfplumber (extraction traditionnelle renforc√©e)"""
    try:
        with pdfplumber.open(file_path) as pdf:
            if len(pdf.pages) == 0:
                raise Exception('PDF vide')
            
            # Extraire tout le texte de toutes les pages
            full_text = ""
            for page in pdf.pages:
                page_text = page.extract_text() or ""
                full_text += page_text + "\n"
            
            page = pdf.pages[0]  # Premi√®re page pour tableaux
            
            # Extraire avec regex renforc√©s
            data = {
                'mandate_number': None,
                'socket_label': None,
                'cable': None,
                'cables': [],
                'fibers_by_cable': [],
                'fiber_1': None,
                'fiber_2': None,
                'fiber_3': None,
                'fiber_4': None,
                'phone': None,
                'email': None,
                'full_text': full_text  # Stocker le texte complet pour l'IA
            }
            
            # Mandate number (Disp ID) - patterns multiples
            patterns_mandate = [
                r'Disp\s*ID[:\s]+(\d+)',
                r'Mandat[:\s]*#?(\d+)',
                r'Ordre[:\s]*#?(\d+)',
                r'N¬∞\s*mandat[:\s]*(\d+)',
                r'Mandate[:\s]*(?:number|#)?[:\s]*(\d+)'
            ]
            for pattern in patterns_mandate:
                match = re.search(pattern, full_text, re.IGNORECASE)
                if match:
                    data['mandate_number'] = match.group(1)
                    break
            
            # Socket Label - patterns multiples
            patterns_socket = [
                r'Socket\s*Label[:\s]+(B\.\d+\.\d+\.\d+\.\d+)',
                r'PTO[:\s]+(B\.\d+\.\d+\.\d+\.\d+)',
                r'Socket[:\s]+(B\.\d+\.\d+\.\d+\.\d+)',
                r'Prise[:\s]+(B\.\d+\.\d+\.\d+\.\d+)',
                r'(B\.\d{3,}\.\d{2,}\.\d{2,}\.\d{1,})'
            ]
            for pattern in patterns_socket:
                match = re.search(pattern, full_text, re.IGNORECASE)
                if match:
                    data['socket_label'] = match.group(1)
                    break
            
            # Extraire les tableaux pour les c√¢bles et fibres
            tables = page.extract_tables()
            cables_found = []
            fibers_by_cable = []
            
            if tables:
                for table in tables:
                    if not table or len(table) < 2:
                        continue
                    
                    sp_columns = {}
                    header_row_idx = None
                    cable_column_idx = None
                    
                    # Trouver la ligne d'en-t√™te avec SP1, SP2, SP3, SP4
                    for row_idx, row in enumerate(table):
                        if not row:
                            continue
                        for col_idx, cell in enumerate(row):
                            if cell is None:
                                continue
                            cell_str = str(cell).strip()
                            cell_upper = cell_str.upper()
                            # Patterns pour les SP avec variantes
                            if re.search(r'SP\s*1|SPLICE\s*1', cell_upper):
                                sp_columns['1'] = col_idx
                                header_row_idx = row_idx
                            elif re.search(r'SP\s*2|SPLICE\s*2', cell_upper):
                                sp_columns['2'] = col_idx
                            elif re.search(r'SP\s*3|SPLICE\s*3', cell_upper):
                                sp_columns['3'] = col_idx
                            elif re.search(r'SP\s*4|SPLICE\s*4', cell_upper):
                                sp_columns['4'] = col_idx
                            # Supporter plusieurs langues/variantes pour l'en-t√™te "cable"
                            if cable_column_idx is None:
                                if re.search(r'c√¢bl|cabl|kabel|cable', cell_str, re.IGNORECASE) and not re.search(r'long|l√§ng|length', cell_str, re.IGNORECASE):
                                    cable_column_idx = col_idx
                        if header_row_idx is not None and (sp_columns or cable_column_idx is not None):
                            break
                    
                    if header_row_idx is None:
                        continue
                    
                    # Parcourir les lignes de donn√©es
                    for data_row_idx in range(header_row_idx + 1, len(table)):
                        data_row = table[data_row_idx]
                        if not data_row:
                            continue
                        
                        # Extraire le c√¢ble
                        cable_value = None
                        if cable_column_idx is not None and cable_column_idx < len(data_row):
                            cable_cell = data_row[cable_column_idx]
                            if cable_cell:
                                cable_text = str(cable_cell).strip()
                                # Nettoyer et valider le c√¢ble
                                if cable_text and not cable_text.isdigit() and len(cable_text) > 2:
                                    cable_value = ' '.join(cable_text.split())
                                    if cable_value and cable_value not in cables_found:
                                        cables_found.append(cable_value)
                        
                        # Extraire les fibres SP1..SP4
                        row_fibers = {
                            "cable": cable_value,
                            "fiber_1": None,
                            "fiber_2": None,
                            "fiber_3": None,
                            "fiber_4": None
                        }
                        
                        for fiber_num, col_idx in sp_columns.items():
                            if col_idx < len(data_row):
                                cell_value = str(data_row[col_idx]).strip()
                                # Accepter nombres et certains patterns alphanum√©riques
                                if cell_value and (cell_value.isdigit() or re.match(r'^[A-Z0-9]{1,4}$', cell_value)):
                                    row_fibers[f"fiber_{fiber_num}"] = cell_value
                        
                        # Ajouter si au moins un c√¢ble ou une fibre
                        if cable_value or any(row_fibers[f"fiber_{n}"] for n in ['1','2','3','4']):
                            fibers_by_cable.append(row_fibers)
                    
                    if fibers_by_cable or cables_found:
                        break
            
            # Nettoyer les c√¢bles
            cleaned_cables = []
            for cable in cables_found:
                clean = ' '.join(str(cable).split())
                if clean and clean not in cleaned_cables:
                    cleaned_cables.append(clean)
            
            data['cables'] = cleaned_cables
            if cleaned_cables:
                data['cable'] = " / ".join(cleaned_cables)
            
            # Si une ligne de fibres n'a pas de `cable` mais des valeurs de fibre,
            # tenter de remplir avec le c√¢ble d√©tect√© globalement ou le dernier connu.
            if fibers_by_cable:
                last_known = None
                for row in fibers_by_cable:
                    if row.get('cable'):
                        last_known = row['cable']
                    else:
                        # Si on a un seul c√¢ble d√©tect√© globalement, l'utiliser
                        if len(cleaned_cables) == 1:
                            row['cable'] = cleaned_cables[0]
                            last_known = row['cable']
                        elif last_known:
                            row['cable'] = last_known

            data['fibers_by_cable'] = fibers_by_cable
            
            # Fusionner les fibres (premi√®re valeur non nulle par colonne)
            for n in ['1','2','3','4']:
                if data[f"fiber_{n}"] is None:
                    for row in fibers_by_cable:
                        if row.get(f"fiber_{n}"):
                            data[f"fiber_{n}"] = row[f"fiber_{n}"]
                            break
            
            # Phone - patterns multiples renforc√©s
            phone_patterns = [
                r'\+41\s*\d{2}\s*\d{3}\s*\d{2}\s*\d{2}',
                r'\+41\d{9}',
                r'0\d{2}\s*\d{3}\s*\d{2}\s*\d{2}',
                r'Tel[:\s]*\+?41?\s*\d{2}\s*\d{3}\s*\d{2}\s*\d{2}',
                r'Phone[:\s]*\+?41?\s*\d{2}\s*\d{3}\s*\d{2}\s*\d{2}',
                r'T√©l[:\s]*\+?41?\s*\d{2}\s*\d{3}\s*\d{2}\s*\d{2}'
            ]
            for pattern in phone_patterns:
                match = re.search(pattern, full_text, re.IGNORECASE)
                if match:
                    data['phone'] = match.group(0).replace(' ', '')
                    break
            
            # Email - patterns renforc√©s
            email_patterns = [
                r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',
                r'Email[:\s]*([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,})',
                r'E-mail[:\s]*([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,})'
            ]
            for pattern in email_patterns:
                match = re.search(pattern, full_text, re.IGNORECASE)
                if match:
                    data['email'] = match.group(1) if match.lastindex else match.group(0)
                    break
            
            return data
            
    except Exception as e:
        print(f'Erreur extraction PDF: {e}')
        raise


def extract_with_ai(full_text, file_name):
    """Extrait les donn√©es du PDF en utilisant le mod√®le IA Qwen2.5:1.5b"""
    try:
        print(f"ü§ñ D√©but extraction IA pour: {file_name}")
        
        # Pr√©parer le prompt pour le mod√®le
        prompt = f"""Tu es un assistant d'extraction de donn√©es de mandats de fibre optique Swisscom. Analyse le texte suivant et extrait les informations structur√©es.

Texte du document:
{full_text[:4000]}

Instructions:
- Extrais UNIQUEMENT les informations pr√©sentes dans le texte
- Ne devine pas, ne fabrique pas de donn√©es
- Retourne un objet JSON valide avec ces champs (null si non trouv√©):
  * mandate_number: num√©ro du mandat/Disp ID
  * socket_label: r√©f√©rence PTO/Socket (format B.xxx.xx.xx.x)
  * cable: nom du c√¢ble d'alimentation
  * fiber_1, fiber_2, fiber_3, fiber_4: num√©ros de fibres (SP1, SP2, SP3, SP4)
  * phone: num√©ro de t√©l√©phone (format +41...)
  * email: adresse email du contact
  * address: adresse compl√®te du site
  * client_name: nom du client

R√©ponds UNIQUEMENT avec le JSON, sans texte suppl√©mentaire."""

        print(f"üîÑ Appel API Ollama ({OLLAMA_MODEL})...")
        
        # Appeler l'API Ollama
        response = requests.post(
            OLLAMA_API_URL,
            json={
                "model": OLLAMA_MODEL,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.1,  # Tr√®s d√©terministe pour extraction
                    "top_p": 0.9,
                    "num_predict": 500
                }
            },
            timeout=60
        )
        
        if response.status_code != 200:
            print(f"‚ùå Erreur API Ollama: {response.status_code} - {response.text}")
            return None
        
        result = response.json()
        duration = result.get('total_duration', 0) / 1e9
        print(f"‚è±Ô∏è Dur√©e traitement IA: {duration:.2f}s")
        
        ai_response = result.get('response', '').strip()
        print(f"üìù R√©ponse IA (premiers 200 car): {ai_response[:200]}...")
        
        # Extraire le JSON de la r√©ponse
        # Le mod√®le peut entourer le JSON avec ```json...``` ou ajouter du texte
        # Nettoyer d'abord les blocs markdown
        cleaned_response = re.sub(r'```json\s*', '', ai_response)
        cleaned_response = re.sub(r'```\s*$', '', cleaned_response)
        
        # Chercher le JSON dans la r√©ponse nettoy√©e
        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', cleaned_response, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            ai_data = json.loads(json_str)
            
            # Nettoyer les valeurs null/vides
            cleaned_data = {}
            for key, value in ai_data.items():
                if value and value != "null" and value != "None":
                    cleaned_data[key] = value
            
            print(f"‚úÖ IA a extrait {len(cleaned_data)} champs: {list(cleaned_data.keys())}")
            return cleaned_data
        else:
            print(f"‚ö†Ô∏è Pas de JSON trouv√© dans la r√©ponse IA: {ai_response[:200]}")
            return None
            
    except requests.Timeout:
        print(f"‚è±Ô∏è Timeout lors de l'appel √† l'API Ollama pour {file_name}")
        return None
    except requests.RequestException as e:
        print(f"üåê Erreur r√©seau lors de l'appel √† l'API Ollama: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"üìÑ Erreur parsing JSON de la r√©ponse IA: {e}")
        print(f"R√©ponse brute: {ai_response[:500]}")
        return None
    except Exception as e:
        print(f"‚ùå Erreur extraction IA: {e}")
        import traceback
        traceback.print_exc()
        return None


def merge_extractions(traditional_data, ai_data):
    """Fusionne intelligemment les r√©sultats de l'extraction traditionnelle et de l'IA"""
    merged = traditional_data.copy()
    
    if not ai_data:
        merged['ai_contribution'] = False
        print("‚ÑπÔ∏è Aucune contribution IA (ai_data est None ou vide)")
        return merged
    
    print(f"üîÄ Fusion des donn√©es - IA a fourni: {list(ai_data.keys())}")
    ai_filled_fields = []
    
    # Liste des champs √† fusionner
    fields = ['mandate_number', 'socket_label', 'cable', 'phone', 'email', 
              'fiber_1', 'fiber_2', 'fiber_3', 'fiber_4', 'address', 'client_name']
    
    for field in fields:
        ai_value = ai_data.get(field)
        traditional_value = merged.get(field)
        
        # Si l'extraction traditionnelle n'a rien trouv√© et l'IA oui
        if (not traditional_value or traditional_value == '') and ai_value:
            merged[field] = ai_value
            ai_filled_fields.append(field)
            print(f"  ‚úÖ IA compl√®te '{field}': {ai_value}")
        # Si les deux ont trouv√© quelque chose mais que c'est diff√©rent
        # On fait confiance √† l'extraction traditionnelle mais on ajoute une note
        elif traditional_value and ai_value and str(traditional_value) != str(ai_value):
            # Pour certains champs critiques, on pr√©f√®re l'extraction traditionnelle
            if field in ['mandate_number', 'socket_label']:
                merged[f'{field}_ai_alternative'] = ai_value
                print(f"  ‚ÑπÔ∏è Conflit '{field}': traditionnel={traditional_value}, IA={ai_value} (garde traditionnel)")
    
    merged['ai_contribution'] = len(ai_filled_fields) > 0
    merged['ai_filled_fields'] = ai_filled_fields
    
    print(f"üìä R√©sultat fusion: {len(ai_filled_fields)} champs compl√©t√©s par IA: {ai_filled_fields}")
    print(f"   ai_contribution = {merged['ai_contribution']}")
    
    return merged

@app.route('/api/analyze-pdf', methods=['POST', 'OPTIONS'])
def analyze_pdf():
    """Analyse les PDF envoy√©s avec double extraction (traditionnelle + IA)"""
    if request.method == 'OPTIONS':
        return '', 204
    
    if 'pdfs' not in request.files:
        return jsonify({'success': False, 'error': 'Aucun fichier envoy√©'}), 400
    
    files = request.files.getlist('pdfs')
    if not files:
        return jsonify({'success': False, 'error': 'Aucun fichier s√©lectionn√©'}), 400
    
    results = []
    
    for file in files:
        if not file.filename.lower().endswith('.pdf'):
            results.append({
                'success': False,
                'file_name': file.filename,
                'error': 'Fichier invalide (PDF requis)'
            })
            continue
        
        try:
            # Sauvegarder temporairement
            temp_path = f'/tmp/{file.filename}'
            file.save(temp_path)
            
            print(f"\n{'='*60}")
            print(f"üìÑ Traitement: {file.filename}")
            print(f"{'='*60}")
            
            # EXTRACTION PARALL√àLE : Traditionnelle + IA
            print("üöÄ Lancement extraction parall√®le (Traditionnelle + IA)...")
            
            with ThreadPoolExecutor(max_workers=2) as executor:
                # Lance l'extraction traditionnelle
                print("  üìù Thread 1: Extraction traditionnelle...")
                future_traditional = executor.submit(extract_pdf_data, temp_path)
                
                # On attend le texte de l'extraction traditionnelle pour l'IA
                traditional_data = future_traditional.result()
                print(f"  ‚úÖ Extraction traditionnelle termin√©e")
                print(f"     Champs trouv√©s: {[k for k, v in traditional_data.items() if v and k != 'full_text']}")
                
                full_text = traditional_data.get('full_text', '')
                
                # Lance l'extraction IA avec le texte
                print(f"  ü§ñ Thread 2: Extraction IA (texte: {len(full_text)} caract√®res)...")
                future_ai = executor.submit(extract_with_ai, full_text, file.filename)
                ai_data = future_ai.result()
                
                if ai_data:
                    print(f"  ‚úÖ Extraction IA termin√©e")
                    print(f"     Champs trouv√©s: {list(ai_data.keys())}")
                else:
                    print(f"  ‚ö†Ô∏è Extraction IA n'a rien retourn√©")
            
            print("\nüîÄ Fusion des extractions...")
            # Fusionner les deux sources
            merged_data = merge_extractions(traditional_data, ai_data)
            
            # Supprimer le full_text avant d'envoyer au client (trop volumineux)
            if 'full_text' in merged_data:
                del merged_data['full_text']
            
            # Calculer confiance (am√©lior√©e si l'IA a contribu√©)
            required_fields = ['mandate_number', 'socket_label', 'cable']
            missing = [f for f in required_fields if not merged_data.get(f)]
            confidence = 1.0 - (len(missing) * 0.33)
            confidence = max(0, confidence)
            
            # Bonus de confiance si l'IA a contribu√©
            if merged_data.get('ai_contribution'):
                confidence = min(1.0, confidence + 0.1)
            
            results.append({
                'success': True,
                'file_name': file.filename,
                'data': merged_data,
                'confidence': confidence,
                'needs_review': len(missing) > 0,
                'missing_fields': missing,
                'extraction_sources': {
                    'traditional': True,
                    'ai': ai_data is not None,
                    'ai_contributed': merged_data.get('ai_contribution', False),
                    'ai_fields': merged_data.get('ai_filled_fields', [])
                }
            })
            
            # Nettoyer
            os.remove(temp_path)
            
        except Exception as e:
            results.append({
                'success': False,
                'file_name': file.filename,
                'error': str(e)
            })
    
    return jsonify({
        'success': True,
        'count': len([r for r in results if r['success']]),
        'results': results
    })

@app.route('/health', methods=['GET'])
def health():
    """Health check"""
    return jsonify({'status': 'healthy', 'version': '1.0.0'})

if __name__ == '__main__':
    port = int(os.getenv('PORT', 5000))
    app.run(host='0.0.0.0', port=port, debug=False)
